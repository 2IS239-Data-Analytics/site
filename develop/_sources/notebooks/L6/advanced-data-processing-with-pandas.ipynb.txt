{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing with Pandas, part 2\n",
    "\n",
    "This week we will continue developing our skills using [pandas](https://pandas.pydata.org/) to process real data. \n",
    "The goal of this lesson is to use our data manipulation and analysis skills to detect weather anomalies (stormy winds) in Helsinki, during August 2017.\n",
    "\n",
    "We will cover a number of useful techniques in pandas including:\n",
    "\n",
    "- renaming columns\n",
    "- iterating data frame rows and applying functions\n",
    "- data aggregation\n",
    "- repeating the analysis task \n",
    "\n",
    "\n",
    "## Input data\n",
    "In the lesson this week we are using weather observation data from Helsinki, Finland from August 2017 when a severe thunderstorm \"Kiira\" hit souther Finland. [Kiira caused major damage in different pars of Helsinki](https://yle.fi/uutiset/osasto/news/saturday_night_storm_downs_trees_cuts_electricity_in_the_south/9773250) (*Source:* [YLE](https://yle.fi/uutiset/osasto/news/saturday_night_storm_downs_trees_cuts_electricity_in_the_south/9773250)).\n",
    "\n",
    "\n",
    "\n",
    "![Markku Sipi/ Yle](img/Kiira-storm.PNG)\n",
    "\n",
    "*Photo: Markku Sipi/YLE*\n",
    "\n",
    "\n",
    "Notice that this time, we will read the **original data file** obtained from NOAA without any modifications to the data file (week 5 input data had been modified after downloading it from NOAA). The input data for this week is separated with varying amount of spaces (fixed width). The first lines and columns of the data looks like following:\n",
    "\n",
    "```\n",
    "      USAF  WBAN YR--MODAHRMN DIR SPD GUS CLG SKC L M H  VSB MW MW MW MW AW AW AW AW W TEMP DEWP    SLP  ...\n",
    "    029740 99999 201708040000 114   6 *** *** BKN * * * 25.0 03 ** ** ** ** ** ** ** 2   58   56 1005.6  ...\n",
    "    029740 99999 201708040020 100   6 ***  75 *** * * *  6.2 ** ** ** ** ** ** ** ** *   59   57 ******  ... \n",
    "    029740 99999 201708040050 100   5 ***  60 *** * * *  6.2 ** ** ** ** ** ** ** ** *   59   57 ******  ...\n",
    "    029740 99999 201708040100 123   8 ***  63 OVC * * * 10.0 ** ** ** ** 23 ** ** ** *   59   58 1004.7  ...\n",
    "    \n",
    "```\n",
    "\n",
    "**We will first work with a subset of the data (data for one single day):** [data/6591337447542dat_sample.txt](data/6591337447542dat_sample.txt)**, before repeating the process on a bigger data set (data for the whole month of August):**  [data/6591337447542dat_August.txt](data/6591337447542dat_August.txt).\n",
    "\n",
    "## Reading the data\n",
    "\n",
    "\n",
    "\n",
    "Because the data is **separated with varying amount of spaces**, we need to tell Pandas how to read it. We can control the delimiter with `sep` parameter following the documentation of the function [read_csv()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html):\n",
    "\n",
    "![read_csv sep](img/read-csv-varying-spaces.png)\n",
    "\n",
    "Based on this information, we should be able to separate the columns by varying number spaces of spaces with `sep='\\s+'` -parameter.\n",
    "\n",
    "\n",
    "Our data also included **No Data values** with varying number of `*` -characters which we also need to take into account when reading the data. \n",
    "We can tell pandas to consider those characters as NaNs by specifying `na_values=['*', '**', '***', '****', '*****', '******']`.\n",
    "\n",
    "- Let's start by importing pandas and reading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fp = \"data/6591337447542dat_sample.txt\"\n",
    "\n",
    "# Read data using varying amount of spaces as separator and specifying * characters as NoData values\n",
    "data = pd.read_csv(fp, sep='\\s+', na_values=['*', '**', '***', '****', '*****', '******'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's see how the data looks by printing the first five rows with `head()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    USAF   WBAN  YR--MODAHRMN  DIR  SPD  GUS   CLG  SKC   L   M ...      SLP  \\\n",
      "0  29740  99999  201708040000  114    6  NaN   NaN  BKN NaN NaN ...   1005.6   \n",
      "1  29740  99999  201708040020  100    6  NaN  75.0  NaN NaN NaN ...      NaN   \n",
      "2  29740  99999  201708040050  100    5  NaN  60.0  NaN NaN NaN ...      NaN   \n",
      "3  29740  99999  201708040100  123    8  NaN  63.0  OVC NaN NaN ...   1004.7   \n",
      "4  29740  99999  201708040120  110    7  NaN  70.0  NaN NaN NaN ...      NaN   \n",
      "\n",
      "     ALT    STP  MAX  MIN  PCP01  PCP06  PCP24  PCPXX   SD  \n",
      "0    NaN  999.2  NaN  NaN    NaN    NaN    NaN    NaN  0.0  \n",
      "1  29.68    NaN  NaN  NaN    NaN    NaN    NaN    NaN  NaN  \n",
      "2  29.65    NaN  NaN  NaN    NaN    NaN    NaN    NaN  NaN  \n",
      "3    NaN  998.4  NaN  NaN    NaN    NaN    NaN    NaN  0.0  \n",
      "4  29.65    NaN  NaN  NaN    NaN    NaN    NaN    NaN  NaN  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming columns\n",
    "\n",
    "- Let's continue and check what columns do we have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so we can see that the data was successfully read to the DataFrame and we also seemed to be able to convert the asterix (\\*) characters into `NaN` -values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['USAF', 'WBAN', 'YR--MODAHRMN', 'DIR', 'SPD', 'GUS', 'CLG', 'SKC', 'L',\n",
       "       'M', 'H', 'VSB', 'MW', 'MW.1', 'MW.2', 'MW.3', 'AW', 'AW.1', 'AW.2',\n",
       "       'AW.3', 'W', 'TEMP', 'DEWP', 'SLP', 'ALT', 'STP', 'MAX', 'MIN', 'PCP01',\n",
       "       'PCP06', 'PCP24', 'PCPXX', 'SD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are quite many columns, however, we won't be needing all of them in our thunderstorm analysis.\n",
    "\n",
    "- Let's select only columns that we might need for detecting unexceptional weather conditions: `'YR--MODAHRMN', 'DIR', 'SPD', 'GUS','TEMP', 'MAX', 'MIN'`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a list of columns that will be selected from the DataFrame\n",
    "select_cols = ['YR--MODAHRMN', 'DIR', 'SPD', 'GUS','TEMP', 'MAX', 'MIN']\n",
    "\n",
    "# Do the selection\n",
    "data = data[select_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's see what our data looks like now by printing **last** 5 rows and the datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YR--MODAHRMN  DIR  SPD   GUS  TEMP  MAX  MIN\n",
      "67  201708042220  180   11   NaN    61  NaN  NaN\n",
      "68  201708042250  190    8   NaN    59  NaN  NaN\n",
      "69  201708042300  200    9  11.0    60  NaN  NaN\n",
      "70  201708042320  190    8   NaN    59  NaN  NaN\n",
      "71  201708042350  190    8   NaN    59  NaN  NaN\n",
      "\n",
      "Data-types:\n",
      "\n",
      "YR--MODAHRMN      int64\n",
      "DIR               int64\n",
      "SPD               int64\n",
      "GUS             float64\n",
      "TEMP              int64\n",
      "MAX             float64\n",
      "MIN             float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Show last five rows\n",
    "print(data.tail())\n",
    "\n",
    "# Check the data types\n",
    "print(\"\\nData-types:\\n\")\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column names that we have are somewhat ackward. Let's change them into more intuitive ones. \n",
    "This can be done easily using the `rename()` -method and a dictionary that lists old and new column names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**dictionaries**\n",
    "\n",
    "[Dictionary](https://docs.python.org/2/tutorial/datastructures.html#dictionaries) is a spesific data structure in Python for storing key-value pairs. During this course, we will use dictionaries mainly when renaming columns in a pandas series, but dictionaries are useful for many different purposes! For more information about Python dictionaries, check out [this tutorial](https://realpython.com/python-dicts/).\n",
    "    \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define the new column names using a [dictionary](https://www.tutorialspoint.com/python/python_dictionary.htm) where we determine \"`key: value`\" -pairs, in which the original column name (the one which will be replaced) is the key, and the new column name is the value.\n",
    "\n",
    "- Let's change:\n",
    "   \n",
    "   - `YR--MODAHRMN` column into `TIME`, \n",
    "   - `SPD` into `SPEED`, and\n",
    "   - `GUS` into `GUST`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GUS': 'GUST', 'YR--MODAHRMN': 'TIME', 'SPD': 'SPEED'}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Create the dictionary with old and new names\n",
    "name_conversion_dict = {'YR--MODAHRMN': 'TIME', 'SPD': 'SPEED', 'GUS': 'GUST'}\n",
    "\n",
    "# Let's see what they look like and what is the type\n",
    "print(name_conversion_dict)\n",
    "print(type(name_conversion_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above we can see that we have successfully created a dictionary that is of type `dict`. \n",
    "\n",
    "- Now we can change the column names by passing that dictionary into parameter `columns` in `rename()` -function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TIME', 'DIR', 'SPEED', 'GUST', 'TEMP', 'MAX', 'MIN'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Rename the columns\n",
    "data = data.rename(columns=name_conversion_dict)\n",
    "\n",
    "# Print the new columns\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect, now our column names are more easy to understand and use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reminder: basic calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert the wind speeds into meters per second values (m/s) as they are more familiar to us in Finland. This can be done with a formula **`m/s = mph x 0.44704`**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Convert speeds from miles to meters\n",
    "data['SPEED'] = data['SPEED']*0.44704\n",
    "data['GUST'] = data['GUST']*0.44704"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME</th>\n",
       "      <th>DIR</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>GUST</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201708040000</td>\n",
       "      <td>114</td>\n",
       "      <td>2.68224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201708040020</td>\n",
       "      <td>100</td>\n",
       "      <td>2.68224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201708040050</td>\n",
       "      <td>100</td>\n",
       "      <td>2.23520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201708040100</td>\n",
       "      <td>123</td>\n",
       "      <td>3.57632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201708040120</td>\n",
       "      <td>110</td>\n",
       "      <td>3.12928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>201708040150</td>\n",
       "      <td>100</td>\n",
       "      <td>2.68224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>201708040200</td>\n",
       "      <td>138</td>\n",
       "      <td>4.47040</td>\n",
       "      <td>5.81152</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>201708040220</td>\n",
       "      <td>120</td>\n",
       "      <td>4.47040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>201708040250</td>\n",
       "      <td>100</td>\n",
       "      <td>4.02336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>201708040300</td>\n",
       "      <td>108</td>\n",
       "      <td>4.02336</td>\n",
       "      <td>5.36448</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TIME  DIR    SPEED     GUST  TEMP  MAX  MIN\n",
       "0  201708040000  114  2.68224      NaN    58  NaN  NaN\n",
       "1  201708040020  100  2.68224      NaN    59  NaN  NaN\n",
       "2  201708040050  100  2.23520      NaN    59  NaN  NaN\n",
       "3  201708040100  123  3.57632      NaN    59  NaN  NaN\n",
       "4  201708040120  110  3.12928      NaN    59  NaN  NaN\n",
       "5  201708040150  100  2.68224      NaN    61  NaN  NaN\n",
       "6  201708040200  138  4.47040  5.81152    59  NaN  NaN\n",
       "7  201708040220  120  4.47040      NaN    59  NaN  NaN\n",
       "8  201708040250  100  4.02336      NaN    59  NaN  NaN\n",
       "9  201708040300  108  4.02336  5.36448    59  NaN  NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's check some basic statistics to understand our data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               TIME         DIR      SPEED       GUST       TEMP        MAX  \\\n",
      "count  7.200000e+01   72.000000  72.000000  20.000000  72.000000   2.000000   \n",
      "mean   2.017080e+11  229.555556   5.153378   7.912608  61.513889  66.500000   \n",
      "std    6.973834e+02  215.759248   1.679342   2.266045   3.175580   3.535534   \n",
      "min    2.017080e+11   80.000000   2.235200   4.917440  58.000000  64.000000   \n",
      "25%    2.017080e+11  117.750000   4.023360   5.811520  59.000000  65.250000   \n",
      "50%    2.017080e+11  200.000000   4.917440   7.152640  61.000000  66.500000   \n",
      "75%    2.017080e+11  220.000000   6.705600   9.946640  64.000000  67.750000   \n",
      "max    2.017080e+11  990.000000   8.940800  12.964160  69.000000  69.000000   \n",
      "\n",
      "             MIN  \n",
      "count   2.000000  \n",
      "mean   57.000000  \n",
      "std     1.414214  \n",
      "min    56.000000  \n",
      "25%    56.500000  \n",
      "50%    57.000000  \n",
      "75%    57.500000  \n",
      "max    58.000000  \n"
     ]
    }
   ],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okey so from here we can see that there are varying number of observations per column (see the `count` -information). \n",
    "\n",
    "For example `SPD` and `TEMP` columns have 72 observations whereas `GUST` has only 20 observations and `MAX` and `MIN` have only 2 observations. From here we can already guess that `MAX` and `MIN` attributes are most probably not going to be useful for us. However, `GUST` might be.\n",
    "\n",
    "- Let's explore further our data by checking the first 30 rows of it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            TIME  DIR    SPEED      GUST  TEMP   MAX   MIN\n",
      "0   201708040000  114  2.68224       NaN    58   NaN   NaN\n",
      "1   201708040020  100  2.68224       NaN    59   NaN   NaN\n",
      "2   201708040050  100  2.23520       NaN    59   NaN   NaN\n",
      "3   201708040100  123  3.57632       NaN    59   NaN   NaN\n",
      "4   201708040120  110  3.12928       NaN    59   NaN   NaN\n",
      "5   201708040150  100  2.68224       NaN    61   NaN   NaN\n",
      "6   201708040200  138  4.47040   5.81152    59   NaN   NaN\n",
      "7   201708040220  120  4.47040       NaN    59   NaN   NaN\n",
      "8   201708040250  100  4.02336       NaN    59   NaN   NaN\n",
      "9   201708040300  108  4.02336   5.36448    59   NaN   NaN\n",
      "10  201708040320   90  3.57632       NaN    59   NaN   NaN\n",
      "11  201708040350   80  4.02336       NaN    59   NaN   NaN\n",
      "12  201708040400  102  4.91744   6.70560    58   NaN   NaN\n",
      "13  201708040420   80  4.47040       NaN    59   NaN   NaN\n",
      "14  201708040450   80  4.47040       NaN    59   NaN   NaN\n",
      "15  201708040500  119  5.36448   7.59968    58   NaN   NaN\n",
      "16  201708040520  990  4.91744       NaN    59   NaN   NaN\n",
      "17  201708040550  100  5.81152       NaN    59   NaN   NaN\n",
      "18  201708040600  121  7.15264  10.28192    58  64.0  56.0\n",
      "19  201708040620  110  6.70560       NaN    59   NaN   NaN\n",
      "20  201708040650  100  6.70560       NaN    59   NaN   NaN\n",
      "21  201708040700  119  6.25856   9.83488    58   NaN   NaN\n",
      "22  201708040720  990  6.25856       NaN    59   NaN   NaN\n",
      "23  201708040750  100  5.81152       NaN    59   NaN   NaN\n",
      "24  201708040800  125  4.47040   6.70560    58   NaN   NaN\n",
      "25  201708040820  990  4.02336       NaN    59   NaN   NaN\n",
      "26  201708040850  100  3.12928       NaN    59   NaN   NaN\n",
      "27  201708040900  107  3.57632       NaN    59   NaN   NaN\n",
      "28  201708040920  990  3.12928       NaN    59   NaN   NaN\n",
      "29  201708040950  990  2.68224       NaN    61   NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "print(data.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okey, so from here we can actually see that the **`GUST`** column contains information only on an hourly level. That might be useful! Let's keep this in mind.\n",
    "\n",
    "**REMEMBER**: Whenever starting a data analysis with new dataset, it is highly useful to explore the data by calculating basic statistics from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using your own functions in pandas \n",
    "\n",
    "Now it's again time to convert temperatures from Fahrenheit to Celsius! Yes, we have already done this many times before, but this time we will learn how to apply self-made functions to data in a pandas DataFrame.\n",
    "**In short, our task is to define a function for the temperature conversion, and to apply this function for each Celsius value on each row of the DataFrame. Output celsius values should be stored in a new column called** `TEMP_C`.\n",
    "\n",
    "Knowing how to use your own function in pandas can be really useful when doing your own analyses. Here, we will introduce two different approaches for using function in pandas. First, we will see how we can apply the function row-by-row using a `for`-loop and the `DataFrame.iterrows()`-method, and then we will learn how to apply the method to all rows at once using [DataFrame.apply](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.apply.html).\n",
    "\n",
    "For both of these approaches, we first need to define our temperature conversion function from Fahrenheit to Celsius:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fahr_to_celsius(temp_fahrenheit):\n",
    "    \"\"\"\n",
    "    Function to convert Fahrenheit temperature into Celsius.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    temp_fahrenheit: int | float\n",
    "        Input temperature in Fahrenheit (should be a number)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    Temperature in Celsius (float)\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the Fahrenheit into Celsius and return it\n",
    "    converted_temp = (temp_fahrenheit - 32) / 1.8\n",
    "    return converted_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** with such a simple example, we could use the function direcly on a column in the DataFrame in order to conver the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME</th>\n",
       "      <th>DIR</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>GUST</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>TEMP_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201708040000</td>\n",
       "      <td>114</td>\n",
       "      <td>2.68224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201708040020</td>\n",
       "      <td>100</td>\n",
       "      <td>2.68224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201708040050</td>\n",
       "      <td>100</td>\n",
       "      <td>2.23520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201708040100</td>\n",
       "      <td>123</td>\n",
       "      <td>3.57632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201708040120</td>\n",
       "      <td>110</td>\n",
       "      <td>3.12928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TIME  DIR    SPEED  GUST  TEMP  MAX  MIN     TEMP_C\n",
       "0  201708040000  114  2.68224   NaN    58  NaN  NaN  14.444444\n",
       "1  201708040020  100  2.68224   NaN    59  NaN  NaN  15.000000\n",
       "2  201708040050  100  2.23520   NaN    59  NaN  NaN  15.000000\n",
       "3  201708040100  123  3.57632   NaN    59  NaN  NaN  15.000000\n",
       "4  201708040120  110  3.12928   NaN    59  NaN  NaN  15.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"TEMP_C\"] = fahr_to_celsius(data[\"TEMP\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to do something more complicated, we need to know how to apply the function row-by-row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating over rows\n",
    "\n",
    "We can iterate over the rows of Pandas DataFrame by using the `iterrows()` -method and use the function one row at a time.\n",
    "\n",
    "\n",
    "When iterating over the rows in our `DataFrame`, it is noteworthy to understand that the Pandas actually keeps track on the `index` value as well. Hence, the contents of a single row actually contains not only the values, but also the `index` of that row (each row is a pandas Series!). \n",
    "\n",
    "- Let's see how `iterrows()` works by printing out the `TEMP` value on each row using a `for`-loop:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0\n",
      "Temp F: 58.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the rows\n",
    "for idx, row in data.iterrows():\n",
    "    # Print the index value\n",
    "    print('Index:', idx)\n",
    "    \n",
    "    # Print the row\n",
    "    print('Temp F:', row[\"TEMP\"], \"\\n\")\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**break**\n",
    "\n",
    "When developing a for-loop, you don't always need to go trough the whole loop if you just want to test things out. \n",
    "[break](https://www.tutorialspoint.com/python/python_break_statement.htm) statement in Python terminates the current loop after the first iteration and we used it here just to test check out the values on the first row.\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the `idx` variable indeed contains the index value at position 0 (the first row) and the `row` variable contains all the data from that given row stored as a pandas `Series`.\n",
    "\n",
    "- Let's now create an empty column `TEMP_C` for the Celsius temperatures and update the values into that column using the `fahr_to_celsius` function we defined earlier:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty column for the DataFrame where the values will be stored\n",
    "new_column = \"TEMP_C\"\n",
    "data[new_column] = None\n",
    "\n",
    "# Iterate over the rows \n",
    "for idx, row in data.iterrows():\n",
    "    # Convert the Fahrenheit to Celsius\n",
    "    celsius = fahr_to_celsius(row['TEMP'])\n",
    "    \n",
    "    # Update the value of 'Celsius' column with the converted value\n",
    "    data.at[idx, new_column] = celsius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**.at or .loc**\n",
    "\n",
    "Here, you could also use `data.loc[idx, new_column] = celsius` to achieve the same result.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's see what we have now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME</th>\n",
       "      <th>DIR</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>GUST</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>TEMP_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201708040000</td>\n",
       "      <td>114</td>\n",
       "      <td>2.68224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.4444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201708040020</td>\n",
       "      <td>100</td>\n",
       "      <td>2.68224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201708040050</td>\n",
       "      <td>100</td>\n",
       "      <td>2.23520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201708040100</td>\n",
       "      <td>123</td>\n",
       "      <td>3.57632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201708040120</td>\n",
       "      <td>110</td>\n",
       "      <td>3.12928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>201708040150</td>\n",
       "      <td>100</td>\n",
       "      <td>2.68224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.1111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>201708040200</td>\n",
       "      <td>138</td>\n",
       "      <td>4.47040</td>\n",
       "      <td>5.81152</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>201708040220</td>\n",
       "      <td>120</td>\n",
       "      <td>4.47040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>201708040250</td>\n",
       "      <td>100</td>\n",
       "      <td>4.02336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>201708040300</td>\n",
       "      <td>108</td>\n",
       "      <td>4.02336</td>\n",
       "      <td>5.36448</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TIME  DIR    SPEED     GUST  TEMP  MAX  MIN   TEMP_C\n",
       "0  201708040000  114  2.68224      NaN    58  NaN  NaN  14.4444\n",
       "1  201708040020  100  2.68224      NaN    59  NaN  NaN       15\n",
       "2  201708040050  100  2.23520      NaN    59  NaN  NaN       15\n",
       "3  201708040100  123  3.57632      NaN    59  NaN  NaN       15\n",
       "4  201708040120  110  3.12928      NaN    59  NaN  NaN       15\n",
       "5  201708040150  100  2.68224      NaN    61  NaN  NaN  16.1111\n",
       "6  201708040200  138  4.47040  5.81152    59  NaN  NaN       15\n",
       "7  201708040220  120  4.47040      NaN    59  NaN  NaN       15\n",
       "8  201708040250  100  4.02336      NaN    59  NaN  NaN       15\n",
       "9  201708040300  108  4.02336  5.36448    59  NaN  NaN       15"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we have converted our temperatures into Celsius by using our self-made function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas DataFrames and Series also have a dedicated method `.apply()` for applying functions on columns (or rows!). When using `.apply()`, we pass the function name (without parenthesis!) as an argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME</th>\n",
       "      <th>DIR</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>GUST</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>TEMP_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201708040000</td>\n",
       "      <td>114</td>\n",
       "      <td>2.68224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201708040020</td>\n",
       "      <td>100</td>\n",
       "      <td>2.68224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201708040050</td>\n",
       "      <td>100</td>\n",
       "      <td>2.23520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201708040100</td>\n",
       "      <td>123</td>\n",
       "      <td>3.57632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201708040120</td>\n",
       "      <td>110</td>\n",
       "      <td>3.12928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TIME  DIR    SPEED  GUST  TEMP  MAX  MIN     TEMP_C\n",
       "0  201708040000  114  2.68224   NaN    58  NaN  NaN  14.444444\n",
       "1  201708040020  100  2.68224   NaN    59  NaN  NaN  15.000000\n",
       "2  201708040050  100  2.23520   NaN    59  NaN  NaN  15.000000\n",
       "3  201708040100  123  3.57632   NaN    59  NaN  NaN  15.000000\n",
       "4  201708040120  110  3.12928   NaN    59  NaN  NaN  15.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"TEMP_C\"] = data[\"TEMP\"].apply(fahr_to_celsius)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** pay attention which column you are applying the function on! Running this code: `data.apply(fahr_to_celsius)` would not give an error, but the results also don't make much sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Should I use .iterrows() or .apply()?**\n",
    "\n",
    "We are teaching the `.iterrows()` method because it helps to understand the structure of a DataFrame and the process of looping trough DataFrame rows. However, using `.apply()` is often more efficient in terms of execution time. \n",
    "    \n",
    "    \n",
    "At this point, the most important thing is that you understand what happens when you are modifying the values in a pandas DataFrame. When doing the course exercises, either of these approaches is ok!\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String manipulation in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pay attention to columns `TIME`, `GUST`, `SPEED` and `TEMP`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME</th>\n",
       "      <th>DIR</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>GUST</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>TEMP_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201708040000</td>\n",
       "      <td>114</td>\n",
       "      <td>2.68224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201708040020</td>\n",
       "      <td>100</td>\n",
       "      <td>2.68224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201708040050</td>\n",
       "      <td>100</td>\n",
       "      <td>2.23520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201708040100</td>\n",
       "      <td>123</td>\n",
       "      <td>3.57632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201708040120</td>\n",
       "      <td>110</td>\n",
       "      <td>3.12928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>201708040150</td>\n",
       "      <td>100</td>\n",
       "      <td>2.68224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>201708040200</td>\n",
       "      <td>138</td>\n",
       "      <td>4.47040</td>\n",
       "      <td>5.81152</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>201708040220</td>\n",
       "      <td>120</td>\n",
       "      <td>4.47040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>201708040250</td>\n",
       "      <td>100</td>\n",
       "      <td>4.02336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>201708040300</td>\n",
       "      <td>108</td>\n",
       "      <td>4.02336</td>\n",
       "      <td>5.36448</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>201708040320</td>\n",
       "      <td>90</td>\n",
       "      <td>3.57632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>201708040350</td>\n",
       "      <td>80</td>\n",
       "      <td>4.02336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>201708040400</td>\n",
       "      <td>102</td>\n",
       "      <td>4.91744</td>\n",
       "      <td>6.70560</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>201708040420</td>\n",
       "      <td>80</td>\n",
       "      <td>4.47040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>201708040450</td>\n",
       "      <td>80</td>\n",
       "      <td>4.47040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>201708040500</td>\n",
       "      <td>119</td>\n",
       "      <td>5.36448</td>\n",
       "      <td>7.59968</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>201708040520</td>\n",
       "      <td>990</td>\n",
       "      <td>4.91744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>201708040550</td>\n",
       "      <td>100</td>\n",
       "      <td>5.81152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>201708040600</td>\n",
       "      <td>121</td>\n",
       "      <td>7.15264</td>\n",
       "      <td>10.28192</td>\n",
       "      <td>58</td>\n",
       "      <td>64.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>14.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>201708040620</td>\n",
       "      <td>110</td>\n",
       "      <td>6.70560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            TIME  DIR    SPEED      GUST  TEMP   MAX   MIN     TEMP_C\n",
       "0   201708040000  114  2.68224       NaN    58   NaN   NaN  14.444444\n",
       "1   201708040020  100  2.68224       NaN    59   NaN   NaN  15.000000\n",
       "2   201708040050  100  2.23520       NaN    59   NaN   NaN  15.000000\n",
       "3   201708040100  123  3.57632       NaN    59   NaN   NaN  15.000000\n",
       "4   201708040120  110  3.12928       NaN    59   NaN   NaN  15.000000\n",
       "5   201708040150  100  2.68224       NaN    61   NaN   NaN  16.111111\n",
       "6   201708040200  138  4.47040   5.81152    59   NaN   NaN  15.000000\n",
       "7   201708040220  120  4.47040       NaN    59   NaN   NaN  15.000000\n",
       "8   201708040250  100  4.02336       NaN    59   NaN   NaN  15.000000\n",
       "9   201708040300  108  4.02336   5.36448    59   NaN   NaN  15.000000\n",
       "10  201708040320   90  3.57632       NaN    59   NaN   NaN  15.000000\n",
       "11  201708040350   80  4.02336       NaN    59   NaN   NaN  15.000000\n",
       "12  201708040400  102  4.91744   6.70560    58   NaN   NaN  14.444444\n",
       "13  201708040420   80  4.47040       NaN    59   NaN   NaN  15.000000\n",
       "14  201708040450   80  4.47040       NaN    59   NaN   NaN  15.000000\n",
       "15  201708040500  119  5.36448   7.59968    58   NaN   NaN  14.444444\n",
       "16  201708040520  990  4.91744       NaN    59   NaN   NaN  15.000000\n",
       "17  201708040550  100  5.81152       NaN    59   NaN   NaN  15.000000\n",
       "18  201708040600  121  7.15264  10.28192    58  64.0  56.0  14.444444\n",
       "19  201708040620  110  6.70560       NaN    59   NaN   NaN  15.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check also the column data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TIME        int64\n",
       "DIR         int64\n",
       "SPEED     float64\n",
       "GUST      float64\n",
       "TEMP        int64\n",
       "MAX       float64\n",
       "MIN       float64\n",
       "TEMP_C    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `TIME`column contains several timestamps per hour\n",
    "- `GUST` seems to be measured only once an hour\n",
    "- `SPEED` (wind speed), and `TEMP` seem to be measured every 20 minutes (at minutes XX:00, XX:20 and XX:50).\n",
    "\n",
    "The difference between the time intervals might be a problem as we might not be able to compare e.g. the average wind speeds and the speeds during the gust together as they are measured with different intervals. This kind of mismatch between sampling rates of measurements is actually quite typical when working with real data.\n",
    "\n",
    "We can solve this issue by **aggregating the wind speeds into hourly data** so that the attributes become comparable.\n",
    "First we need to be able to group the values by hour. Let's have a look how we can achieve this using the values in the `TIME` column.\n",
    "\n",
    "Remember, that the original name of the `TIME` column was `'YR--MODAHRMN'`. Based on this information, the first observation in our data set `201708040000` is from 4th of August 2017 at 00:00. There is a systematic pattern in the character string values stored in the `TIME` column, and we can retrieve the information about date+hour by slicing the values in the **`TIME`** -column (i.e. removing the minutes from the end of the value).\n",
    "\n",
    "Doing this requires two steps:\n",
    "  1. Convert the `TIME` column from `int` into `str` datatype.\n",
    "  2. Include only numbers up to hourly accuracy (exclude minutes) by slicing texts\n",
    "\n",
    "- Let's convert the time into string. And check that the data type changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of the column:\n",
      "object\n",
      "\n",
      "Data type of the first value in column:\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Convert to string\n",
    "data['TIME_STR'] = data['TIME'].astype(str)\n",
    "\n",
    "# Check data types\n",
    "print(\"Data type of the column:\")\n",
    "print(data['TIME_STR'].dtypes)\n",
    "\n",
    "print(\"\\nData type of the first value in column:\")\n",
    "print(type(data.at[0, 'TIME_STR']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okey it seems that now we indeed have the `TIME` as `str` datatype as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**String functions**\n",
    "\n",
    "**Note:** All the typical `str` functionalities can be applied to Series of text data with syntax `data['mySeries'].str.<functionToUse>()`.\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we can extract information about day and hour by including only 10 first characters from the text (i.e. excluding the minute-level information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           TIME  DIR    SPEED  GUST  TEMP  MAX  MIN     TEMP_C      TIME_STR  \\\n",
      "0  201708040000  114  2.68224   NaN    58  NaN  NaN  14.444444  201708040000   \n",
      "1  201708040020  100  2.68224   NaN    59  NaN  NaN  15.000000  201708040020   \n",
      "2  201708040050  100  2.23520   NaN    59  NaN  NaN  15.000000  201708040050   \n",
      "3  201708040100  123  3.57632   NaN    59  NaN  NaN  15.000000  201708040100   \n",
      "4  201708040120  110  3.12928   NaN    59  NaN  NaN  15.000000  201708040120   \n",
      "\n",
      "      TIME_DH  \n",
      "0  2017080400  \n",
      "1  2017080400  \n",
      "2  2017080400  \n",
      "3  2017080401  \n",
      "4  2017080401  \n"
     ]
    }
   ],
   "source": [
    "# SLice the string\n",
    "data['TIME_DH'] = data['TIME_STR'].str.slice(start=0, stop=10)\n",
    "\n",
    "# Let's see what we have\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Now we have \"labeled\" the rows based on information about day of the year and hour of the day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**TASK:**\n",
    "\n",
    "- Create a new column `TIME_H` which contains the hour of each row as an integer value. For example, the hour for the first row is `0`.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           TIME  DIR    SPEED  GUST  TEMP  MAX  MIN     TEMP_C      TIME_STR  \\\n",
      "0  201708040000  114  2.68224   NaN    58  NaN  NaN  14.444444  201708040000   \n",
      "1  201708040020  100  2.68224   NaN    59  NaN  NaN  15.000000  201708040020   \n",
      "2  201708040050  100  2.23520   NaN    59  NaN  NaN  15.000000  201708040050   \n",
      "3  201708040100  123  3.57632   NaN    59  NaN  NaN  15.000000  201708040100   \n",
      "4  201708040120  110  3.12928   NaN    59  NaN  NaN  15.000000  201708040120   \n",
      "\n",
      "      TIME_DH  TIME_H  \n",
      "0  2017080400       0  \n",
      "1  2017080400       0  \n",
      "2  2017080400       0  \n",
      "3  2017080401       1  \n",
      "4  2017080401       1  \n"
     ]
    }
   ],
   "source": [
    "# Slice the string to parse the hour from 'TIME_str' column\n",
    "data['TIME_H'] = data['TIME_STR'].str.slice(start=8, stop=10)\n",
    "\n",
    "# Convert the hour text into integer format\n",
    "data['TIME_H'] = data['TIME_H'].astype(int)\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating data in Pandas by grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to calculate the average temperatures, wind speeds, etc. on an hourly basis to enable us\n",
    "to compare all of them to each other.\n",
    "\n",
    "This can be done by aggregating the data, i.e.:\n",
    "\n",
    "  1. **grouping the data** based on hourly values\n",
    "  2. Iterating over those groups and calculating the average values of our attributes\n",
    "  3. Inserting those values into **a new DataFrame** where we store the aggregated data\n",
    "  \n",
    "**--> our input data has 3 rows per hour, the aggregated data frame should only have 1 row per hour!**\n",
    "\n",
    "- Let's first create a new **empty** DataFrame where we will store our aggregated data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new empty DataFrame\n",
    "hourly_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's then **group** our data based on `TIME_DH` attribute that contains the information about the date + hour.\n",
    "\n",
    "- First, check how many unique values the `TIME_DH` column has using the `.nunique()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows 72\n",
      "Number of unique day + hour combinations: 24\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows\", len(data))\n",
    "print(\"Number of unique day + hour combinations:\", data[\"TIME_DH\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, we are currently dealing with data from one day, 3 observations per hour!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, group the data based on `TIME_DH` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data \n",
    "grouped = data.groupby('TIME_DH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's see what we have now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type:\n",
      " <class 'pandas.core.groupby.groupby.DataFrameGroupBy'>\n",
      "Length:\n",
      " 24\n"
     ]
    }
   ],
   "source": [
    "# What is the type?\n",
    "print(\"Type:\\n\", type(grouped))\n",
    "\n",
    "# How many?\n",
    "print(\"Length:\\n\", len(grouped))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okey, interesting. Now we have a new object with type **`DataFrameGroupBy`**. And it seems that we have 24 individual groups in our data, i.e. **one group for each hour of the day**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several methods we can use for extracting information from the grouped data. See [documentation for Pandas GroupBy objects](https://pandas.pydata.org/pandas-docs/stable/reference/groupby.html) for a comprehensive overview. \n",
    "\n",
    "**Checking group names:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2017080417', '2017080422', '2017080421', '2017080400', '2017080408', '2017080423', '2017080412', '2017080419', '2017080418', '2017080409', '2017080407', '2017080405', '2017080411', '2017080415', '2017080401', '2017080420', '2017080404', '2017080410', '2017080402', '2017080413', '2017080416', '2017080414', '2017080406', '2017080403'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the \"names\" of each group\n",
    "grouped.groups.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accessing data for one group:**\n",
    "\n",
    "As you might have noticed earlier, the first hour in hour data is `2017080400` (midnight at 4th of August in 2017).\n",
    "\n",
    "- Let's check the contents of the group named `2017080400`. We can get the values of that hour from the grouped object using the `get_group()` -method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           TIME  DIR    SPEED  GUST  TEMP  MAX  MIN     TEMP_C      TIME_STR  \\\n",
      "0  201708040000  114  2.68224   NaN    58  NaN  NaN  14.444444  201708040000   \n",
      "1  201708040020  100  2.68224   NaN    59  NaN  NaN  15.000000  201708040020   \n",
      "2  201708040050  100  2.23520   NaN    59  NaN  NaN  15.000000  201708040050   \n",
      "\n",
      "      TIME_DH  TIME_H  \n",
      "0  2017080400       0  \n",
      "1  2017080400       0  \n",
      "2  2017080400       0  \n"
     ]
    }
   ],
   "source": [
    "# Specify the time of the first hour (as text)\n",
    "time1 = '2017080400'\n",
    "\n",
    "# Select the group\n",
    "group1 = grouped.get_group(time1)\n",
    "\n",
    "# Let's see what we have\n",
    "print(group1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahaa! As we can see, a single group contains a **DataFrame** with values only for that specific hour. Let's check the DataType of this group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(group1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, one group is a pandas DataFrame! This is really useful, because we can now use all the familiar DataFrame methods for calculating statistics etc for this spesific group. \n",
    "We can, for example, calculate the average values for all variables using the statistical functions that we have seen already (e.g. mean, std, min, max, median, etc.).\n",
    "\n",
    "We can do that by using the `mean()` -function that we already used during the Lesson 5. \n",
    "\n",
    "- Let's calculate the mean for following attributes all at once:\n",
    "   - `DIR`, \n",
    "   - `SPEED`, \n",
    "   - `GUST`, \n",
    "   - `TEMP`, \n",
    "   - `TEMP_C`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIR       104.666667\n",
      "SPEED       2.533227\n",
      "GUST             NaN\n",
      "TEMP       58.666667\n",
      "TEMP_C     14.814815\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Specify the columns that will be part of the calculation\n",
    "mean_cols = ['DIR', 'SPEED', 'GUST', 'TEMP', 'TEMP_C']\n",
    "\n",
    "# Calculate the mean values all at one go\n",
    "mean_values = group1[mean_cols].mean()\n",
    "\n",
    "# Let's see what we have\n",
    "print(mean_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, now we have averaged our data and e.g. the mean Celsius temperature seems to be about right when comparing to the original values above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing to do is to add these mean values into our DataFrame that we created.\n",
    "That can be done with `append()` -function in a quite similar manner as with Python lists. In Pandas the data insertion is not done **inplace** (as when appending to Python lists) so we need to specify that we are updating the aggr_data (using the **`=`** sign). We also need to specify that we ignore the index values of our original DataFrame (i.e. the indices of `mean_values`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          DIR  GUST     SPEED       TEMP     TEMP_C\n",
      "0  104.666667   NaN  2.533227  58.666667  14.814815\n"
     ]
    }
   ],
   "source": [
    "# Add the values into our aggr_data DataFrame that we created in the beginning\n",
    "hourly_data = hourly_data.append(mean_values, ignore_index=True)\n",
    "\n",
    "# Let's see what we have\n",
    "print(hourly_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DIR       104.666667\n",
       "SPEED       2.533227\n",
       "GUST             NaN\n",
       "TEMP       58.666667\n",
       "TEMP_C     14.814815\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, now we have a single row in our new DataFrame where we have aggregated the data based on hourly mean values.\n",
    "Next we could continue doing and insert the average values from other hours in a similar manner but, of course, that is not\n",
    "something that we want to do manually (would require repeating these same steps too many times).\n",
    "Luckily, we can actually iterate over all the groups that we have in our data and do these steps using a **`for`** -loop.\n",
    "\n",
    "When iterating over the groups in our **`DataFrameGroupBy`** -object\n",
    "it is important to understand that a single group in our `DataFrameGroupBy` actually contains not only the actual values, but also information about the **`key`** that was used to do the grouping. Hence, when iterating over the data we need to assign the `key` and the values into separate variables.\n",
    "\n",
    "- Let's see how we can iterate over the groups and print the key and the data from a single group (again using **`break`** to only see what is happening).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key:\n",
      " 2017080400\n",
      "\n",
      "Group:\n",
      "            TIME  DIR    SPEED  GUST  TEMP  MAX  MIN     TEMP_C      TIME_STR  \\\n",
      "0  201708040000  114  2.68224   NaN    58  NaN  NaN  14.444444  201708040000   \n",
      "1  201708040020  100  2.68224   NaN    59  NaN  NaN  15.000000  201708040020   \n",
      "2  201708040050  100  2.23520   NaN    59  NaN  NaN  15.000000  201708040050   \n",
      "\n",
      "      TIME_DH  TIME_H  \n",
      "0  2017080400       0  \n",
      "1  2017080400       0  \n",
      "2  2017080400       0  \n"
     ]
    }
   ],
   "source": [
    "# Iterate over groups\n",
    "for key, group in grouped:\n",
    "    # Print key and group\n",
    "    print(\"Key:\\n\", key)\n",
    "    print(\"\\nGroup:\\n\", group)\n",
    "    \n",
    "    # Stop iteration with break command\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okey so from here we can see that the **`key`** contains the value **`2017080400`** that is the same\n",
    "as the values in **`TIME_dh`** column. Meaning that we, indeed, grouped the values based on that column.\n",
    "\n",
    "- Let's see how we can create a DataFrame where we calculate the mean values for all those weather attributes that we were interested in. I will repeate slightly the earlier steps so that you can see and better understand what is happening.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame for the aggregated values\n",
    "hourly_data = pd.DataFrame()\n",
    "\n",
    "# The columns that we want to aggregate\n",
    "mean_cols = ['DIR', 'SPEED', 'GUST', 'TEMP', 'TEMP_C']\n",
    "\n",
    "# Iterate over the groups\n",
    "for key, group in grouped:\n",
    "   # Aggregate the data\n",
    "   mean_values = group[mean_cols].mean()\n",
    "\n",
    "   # Add the ´key´ (i.e. the date+time information) into the aggregated values\n",
    "   mean_values['TIME_DH'] = key\n",
    "\n",
    "   # Append the aggregated values into the DataFrame\n",
    "   hourly_data = hourly_data.append(mean_values, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's see what we have now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           DIR      GUST     SPEED       TEMP     TEMP_C     TIME_DH\n",
      "0   104.666667       NaN  2.533227  58.666667  14.814815  2017080400\n",
      "1   111.000000       NaN  3.129280  59.666667  15.370370  2017080401\n",
      "2   119.333333   5.81152  4.321387  59.000000  15.000000  2017080402\n",
      "3    92.666667   5.36448  3.874347  59.000000  15.000000  2017080403\n",
      "4    87.333333   6.70560  4.619413  58.666667  14.814815  2017080404\n",
      "5   403.000000   7.59968  5.364480  58.666667  14.814815  2017080405\n",
      "6   110.333333  10.28192  6.854613  58.666667  14.814815  2017080406\n",
      "7   403.000000   9.83488  6.109547  58.666667  14.814815  2017080407\n",
      "8   405.000000   6.70560  3.874347  58.666667  14.814815  2017080408\n",
      "9   695.666667       NaN  3.129280  59.666667  15.370370  2017080409\n",
      "10  225.000000   5.81152  4.768427  61.666667  16.481481  2017080410\n",
      "11  241.666667   8.49376  5.513493  64.000000  17.777778  2017080411\n",
      "12  228.333333   6.70560  5.960533  66.000000  18.888889  2017080412\n",
      "13  229.666667   8.94080  7.152640  67.333333  19.629630  2017080413\n",
      "14  228.666667  12.96416  8.940800  68.333333  20.185185  2017080414\n",
      "15  218.333333  10.72896  7.450667  66.333333  19.074074  2017080415\n",
      "16  214.666667  10.28192  7.152640  65.666667  18.703704  2017080416\n",
      "17  209.666667   8.94080  7.003627  63.666667  17.592593  2017080417\n",
      "18  211.333333  10.28192  5.662507  62.333333  16.851852  2017080418\n",
      "19  203.000000   5.81152  4.023360  61.000000  16.111111  2017080419\n",
      "20  198.000000   5.36448  4.023360  60.666667  15.925926  2017080420\n",
      "21  186.666667       NaN  3.874347  60.666667  15.925926  2017080421\n",
      "22  189.000000   6.70560  4.619413  60.000000  15.555556  2017080422\n",
      "23  193.333333   4.91744  3.725333  59.333333  15.185185  2017080423\n"
     ]
    }
   ],
   "source": [
    "print(hourly_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Now we have aggregated our data based on daily averages and we have a new DataFrame called `hourly_data` where all those aggregated values are stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shortcut: Mean for all groups**\n",
    "\n",
    "We can also achieve the same result by computing the mean of all columns for all groups in the grouped object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME</th>\n",
       "      <th>DIR</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>GUST</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>TEMP_C</th>\n",
       "      <th>TIME_H</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIME_DH</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017080400</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>104.666667</td>\n",
       "      <td>2.533227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.814815</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017080401</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>3.129280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.370370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017080402</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>119.333333</td>\n",
       "      <td>4.321387</td>\n",
       "      <td>5.81152</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017080403</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>92.666667</td>\n",
       "      <td>3.874347</td>\n",
       "      <td>5.36448</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017080404</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>87.333333</td>\n",
       "      <td>4.619413</td>\n",
       "      <td>6.70560</td>\n",
       "      <td>58.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.814815</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017080405</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>403.000000</td>\n",
       "      <td>5.364480</td>\n",
       "      <td>7.59968</td>\n",
       "      <td>58.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.814815</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017080406</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>110.333333</td>\n",
       "      <td>6.854613</td>\n",
       "      <td>10.28192</td>\n",
       "      <td>58.666667</td>\n",
       "      <td>64.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>14.814815</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017080407</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>403.000000</td>\n",
       "      <td>6.109547</td>\n",
       "      <td>9.83488</td>\n",
       "      <td>58.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.814815</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017080408</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>405.000000</td>\n",
       "      <td>3.874347</td>\n",
       "      <td>6.70560</td>\n",
       "      <td>58.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.814815</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017080409</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>695.666667</td>\n",
       "      <td>3.129280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.370370</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017080410</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>4.768427</td>\n",
       "      <td>5.81152</td>\n",
       "      <td>61.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.481481</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017080411</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>241.666667</td>\n",
       "      <td>5.513493</td>\n",
       "      <td>8.49376</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.777778</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017080412</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>228.333333</td>\n",
       "      <td>5.960533</td>\n",
       "      <td>6.70560</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.888889</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017080413</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>229.666667</td>\n",
       "      <td>7.152640</td>\n",
       "      <td>8.94080</td>\n",
       "      <td>67.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.629630</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017080414</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>228.666667</td>\n",
       "      <td>8.940800</td>\n",
       "      <td>12.96416</td>\n",
       "      <td>68.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.185185</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017080415</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>218.333333</td>\n",
       "      <td>7.450667</td>\n",
       "      <td>10.72896</td>\n",
       "      <td>66.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.074074</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017080416</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>214.666667</td>\n",
       "      <td>7.152640</td>\n",
       "      <td>10.28192</td>\n",
       "      <td>65.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.703704</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017080417</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>209.666667</td>\n",
       "      <td>7.003627</td>\n",
       "      <td>8.94080</td>\n",
       "      <td>63.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.592593</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017080418</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>211.333333</td>\n",
       "      <td>5.662507</td>\n",
       "      <td>10.28192</td>\n",
       "      <td>62.333333</td>\n",
       "      <td>69.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>16.851852</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017080419</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>4.023360</td>\n",
       "      <td>5.81152</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.111111</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017080420</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>4.023360</td>\n",
       "      <td>5.36448</td>\n",
       "      <td>60.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.925926</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017080421</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>186.666667</td>\n",
       "      <td>3.874347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.925926</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017080422</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>4.619413</td>\n",
       "      <td>6.70560</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.555556</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017080423</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>193.333333</td>\n",
       "      <td>3.725333</td>\n",
       "      <td>4.91744</td>\n",
       "      <td>59.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.185185</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    TIME         DIR     SPEED      GUST       TEMP   MAX  \\\n",
       "TIME_DH                                                                     \n",
       "2017080400  2.017080e+11  104.666667  2.533227       NaN  58.666667   NaN   \n",
       "2017080401  2.017080e+11  111.000000  3.129280       NaN  59.666667   NaN   \n",
       "2017080402  2.017080e+11  119.333333  4.321387   5.81152  59.000000   NaN   \n",
       "2017080403  2.017080e+11   92.666667  3.874347   5.36448  59.000000   NaN   \n",
       "2017080404  2.017080e+11   87.333333  4.619413   6.70560  58.666667   NaN   \n",
       "2017080405  2.017080e+11  403.000000  5.364480   7.59968  58.666667   NaN   \n",
       "2017080406  2.017080e+11  110.333333  6.854613  10.28192  58.666667  64.0   \n",
       "2017080407  2.017080e+11  403.000000  6.109547   9.83488  58.666667   NaN   \n",
       "2017080408  2.017080e+11  405.000000  3.874347   6.70560  58.666667   NaN   \n",
       "2017080409  2.017080e+11  695.666667  3.129280       NaN  59.666667   NaN   \n",
       "2017080410  2.017080e+11  225.000000  4.768427   5.81152  61.666667   NaN   \n",
       "2017080411  2.017080e+11  241.666667  5.513493   8.49376  64.000000   NaN   \n",
       "2017080412  2.017080e+11  228.333333  5.960533   6.70560  66.000000   NaN   \n",
       "2017080413  2.017080e+11  229.666667  7.152640   8.94080  67.333333   NaN   \n",
       "2017080414  2.017080e+11  228.666667  8.940800  12.96416  68.333333   NaN   \n",
       "2017080415  2.017080e+11  218.333333  7.450667  10.72896  66.333333   NaN   \n",
       "2017080416  2.017080e+11  214.666667  7.152640  10.28192  65.666667   NaN   \n",
       "2017080417  2.017080e+11  209.666667  7.003627   8.94080  63.666667   NaN   \n",
       "2017080418  2.017080e+11  211.333333  5.662507  10.28192  62.333333  69.0   \n",
       "2017080419  2.017080e+11  203.000000  4.023360   5.81152  61.000000   NaN   \n",
       "2017080420  2.017080e+11  198.000000  4.023360   5.36448  60.666667   NaN   \n",
       "2017080421  2.017080e+11  186.666667  3.874347       NaN  60.666667   NaN   \n",
       "2017080422  2.017080e+11  189.000000  4.619413   6.70560  60.000000   NaN   \n",
       "2017080423  2.017080e+11  193.333333  3.725333   4.91744  59.333333   NaN   \n",
       "\n",
       "             MIN     TEMP_C  TIME_H  \n",
       "TIME_DH                              \n",
       "2017080400   NaN  14.814815       0  \n",
       "2017080401   NaN  15.370370       1  \n",
       "2017080402   NaN  15.000000       2  \n",
       "2017080403   NaN  15.000000       3  \n",
       "2017080404   NaN  14.814815       4  \n",
       "2017080405   NaN  14.814815       5  \n",
       "2017080406  56.0  14.814815       6  \n",
       "2017080407   NaN  14.814815       7  \n",
       "2017080408   NaN  14.814815       8  \n",
       "2017080409   NaN  15.370370       9  \n",
       "2017080410   NaN  16.481481      10  \n",
       "2017080411   NaN  17.777778      11  \n",
       "2017080412   NaN  18.888889      12  \n",
       "2017080413   NaN  19.629630      13  \n",
       "2017080414   NaN  20.185185      14  \n",
       "2017080415   NaN  19.074074      15  \n",
       "2017080416   NaN  18.703704      16  \n",
       "2017080417   NaN  17.592593      17  \n",
       "2017080418  58.0  16.851852      18  \n",
       "2017080419   NaN  16.111111      19  \n",
       "2017080420   NaN  15.925926      20  \n",
       "2017080421   NaN  15.925926      21  \n",
       "2017080422   NaN  15.555556      22  \n",
       "2017080423   NaN  15.185185      23  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Pandas datetime**\n",
    "\n",
    "So far, we have been operating with time using integers and character strings. Python (and pandas) come with more advanced approaches for handling dates and times. In pandas, we can convert dates and times into a new data type [datetime](https://docs.python.org/3.7/library/datetime.html) using [pandas.to_datetime](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html) function. First, it is important to understand the structure of the input data in order to avoid erroneous conversions, and that's why we first focus on string slicing before introducing the datetime functionalities. \n",
    "    \n",
    "Here is one example of how to convert the `TIME_STR`-column in our data set to datetime:\n",
    "    \n",
    "```\n",
    "# Convert to datetime\n",
    "data[\"DATE\"] = pd.to_datetime(data[\"TIME_STR\"], format='%Y%m%d%H', exact=False)\n",
    "\n",
    "```\n",
    "\n",
    "    \n",
    "In this example, `format` defines the output datetime format according to strftime(format) method: https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior. `exact=False` drops out minutes and secods, because they are not included in the specified formatting.\n",
    "    \n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2017-08-04 00:00:00\n",
       "1   2017-08-04 00:00:00\n",
       "2   2017-08-04 00:00:00\n",
       "3   2017-08-04 01:00:00\n",
       "4   2017-08-04 01:00:00\n",
       "Name: DATE, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to datetime\n",
    "data[\"DATE\"] = pd.to_datetime(data[\"TIME_STR\"], format='%Y%m%d%H', exact=False)\n",
    "data[\"DATE\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: in this case, the data type of the values is `datetime`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we could group the data based on the new datetime column and retrieve the mean values for each column:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME</th>\n",
       "      <th>DIR</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>GUST</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>TEMP_C</th>\n",
       "      <th>TIME_H</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-04 00:00:00</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>104.666667</td>\n",
       "      <td>2.533227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.814815</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 01:00:00</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>3.129280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.370370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 02:00:00</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>119.333333</td>\n",
       "      <td>4.321387</td>\n",
       "      <td>5.81152</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 03:00:00</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>92.666667</td>\n",
       "      <td>3.874347</td>\n",
       "      <td>5.36448</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 04:00:00</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>87.333333</td>\n",
       "      <td>4.619413</td>\n",
       "      <td>6.70560</td>\n",
       "      <td>58.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.814815</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 05:00:00</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>403.000000</td>\n",
       "      <td>5.364480</td>\n",
       "      <td>7.59968</td>\n",
       "      <td>58.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.814815</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 06:00:00</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>110.333333</td>\n",
       "      <td>6.854613</td>\n",
       "      <td>10.28192</td>\n",
       "      <td>58.666667</td>\n",
       "      <td>64.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>14.814815</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 07:00:00</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>403.000000</td>\n",
       "      <td>6.109547</td>\n",
       "      <td>9.83488</td>\n",
       "      <td>58.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.814815</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 08:00:00</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>405.000000</td>\n",
       "      <td>3.874347</td>\n",
       "      <td>6.70560</td>\n",
       "      <td>58.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.814815</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 09:00:00</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>695.666667</td>\n",
       "      <td>3.129280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.370370</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 10:00:00</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>4.768427</td>\n",
       "      <td>5.81152</td>\n",
       "      <td>61.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.481481</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 11:00:00</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>241.666667</td>\n",
       "      <td>5.513493</td>\n",
       "      <td>8.49376</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.777778</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 12:00:00</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>228.333333</td>\n",
       "      <td>5.960533</td>\n",
       "      <td>6.70560</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.888889</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 13:00:00</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>229.666667</td>\n",
       "      <td>7.152640</td>\n",
       "      <td>8.94080</td>\n",
       "      <td>67.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.629630</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 14:00:00</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>228.666667</td>\n",
       "      <td>8.940800</td>\n",
       "      <td>12.96416</td>\n",
       "      <td>68.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.185185</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 15:00:00</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>218.333333</td>\n",
       "      <td>7.450667</td>\n",
       "      <td>10.72896</td>\n",
       "      <td>66.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.074074</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 16:00:00</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>214.666667</td>\n",
       "      <td>7.152640</td>\n",
       "      <td>10.28192</td>\n",
       "      <td>65.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.703704</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 17:00:00</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>209.666667</td>\n",
       "      <td>7.003627</td>\n",
       "      <td>8.94080</td>\n",
       "      <td>63.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.592593</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 18:00:00</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>211.333333</td>\n",
       "      <td>5.662507</td>\n",
       "      <td>10.28192</td>\n",
       "      <td>62.333333</td>\n",
       "      <td>69.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>16.851852</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 19:00:00</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>4.023360</td>\n",
       "      <td>5.81152</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.111111</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 20:00:00</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>4.023360</td>\n",
       "      <td>5.36448</td>\n",
       "      <td>60.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.925926</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 21:00:00</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>186.666667</td>\n",
       "      <td>3.874347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.925926</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 22:00:00</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>4.619413</td>\n",
       "      <td>6.70560</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.555556</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 23:00:00</th>\n",
       "      <td>2.017080e+11</td>\n",
       "      <td>193.333333</td>\n",
       "      <td>3.725333</td>\n",
       "      <td>4.91744</td>\n",
       "      <td>59.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.185185</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             TIME         DIR     SPEED      GUST       TEMP  \\\n",
       "DATE                                                                           \n",
       "2017-08-04 00:00:00  2.017080e+11  104.666667  2.533227       NaN  58.666667   \n",
       "2017-08-04 01:00:00  2.017080e+11  111.000000  3.129280       NaN  59.666667   \n",
       "2017-08-04 02:00:00  2.017080e+11  119.333333  4.321387   5.81152  59.000000   \n",
       "2017-08-04 03:00:00  2.017080e+11   92.666667  3.874347   5.36448  59.000000   \n",
       "2017-08-04 04:00:00  2.017080e+11   87.333333  4.619413   6.70560  58.666667   \n",
       "2017-08-04 05:00:00  2.017080e+11  403.000000  5.364480   7.59968  58.666667   \n",
       "2017-08-04 06:00:00  2.017080e+11  110.333333  6.854613  10.28192  58.666667   \n",
       "2017-08-04 07:00:00  2.017080e+11  403.000000  6.109547   9.83488  58.666667   \n",
       "2017-08-04 08:00:00  2.017080e+11  405.000000  3.874347   6.70560  58.666667   \n",
       "2017-08-04 09:00:00  2.017080e+11  695.666667  3.129280       NaN  59.666667   \n",
       "2017-08-04 10:00:00  2.017080e+11  225.000000  4.768427   5.81152  61.666667   \n",
       "2017-08-04 11:00:00  2.017080e+11  241.666667  5.513493   8.49376  64.000000   \n",
       "2017-08-04 12:00:00  2.017080e+11  228.333333  5.960533   6.70560  66.000000   \n",
       "2017-08-04 13:00:00  2.017080e+11  229.666667  7.152640   8.94080  67.333333   \n",
       "2017-08-04 14:00:00  2.017080e+11  228.666667  8.940800  12.96416  68.333333   \n",
       "2017-08-04 15:00:00  2.017080e+11  218.333333  7.450667  10.72896  66.333333   \n",
       "2017-08-04 16:00:00  2.017080e+11  214.666667  7.152640  10.28192  65.666667   \n",
       "2017-08-04 17:00:00  2.017080e+11  209.666667  7.003627   8.94080  63.666667   \n",
       "2017-08-04 18:00:00  2.017080e+11  211.333333  5.662507  10.28192  62.333333   \n",
       "2017-08-04 19:00:00  2.017080e+11  203.000000  4.023360   5.81152  61.000000   \n",
       "2017-08-04 20:00:00  2.017080e+11  198.000000  4.023360   5.36448  60.666667   \n",
       "2017-08-04 21:00:00  2.017080e+11  186.666667  3.874347       NaN  60.666667   \n",
       "2017-08-04 22:00:00  2.017080e+11  189.000000  4.619413   6.70560  60.000000   \n",
       "2017-08-04 23:00:00  2.017080e+11  193.333333  3.725333   4.91744  59.333333   \n",
       "\n",
       "                      MAX   MIN     TEMP_C  TIME_H  \n",
       "DATE                                                \n",
       "2017-08-04 00:00:00   NaN   NaN  14.814815       0  \n",
       "2017-08-04 01:00:00   NaN   NaN  15.370370       1  \n",
       "2017-08-04 02:00:00   NaN   NaN  15.000000       2  \n",
       "2017-08-04 03:00:00   NaN   NaN  15.000000       3  \n",
       "2017-08-04 04:00:00   NaN   NaN  14.814815       4  \n",
       "2017-08-04 05:00:00   NaN   NaN  14.814815       5  \n",
       "2017-08-04 06:00:00  64.0  56.0  14.814815       6  \n",
       "2017-08-04 07:00:00   NaN   NaN  14.814815       7  \n",
       "2017-08-04 08:00:00   NaN   NaN  14.814815       8  \n",
       "2017-08-04 09:00:00   NaN   NaN  15.370370       9  \n",
       "2017-08-04 10:00:00   NaN   NaN  16.481481      10  \n",
       "2017-08-04 11:00:00   NaN   NaN  17.777778      11  \n",
       "2017-08-04 12:00:00   NaN   NaN  18.888889      12  \n",
       "2017-08-04 13:00:00   NaN   NaN  19.629630      13  \n",
       "2017-08-04 14:00:00   NaN   NaN  20.185185      14  \n",
       "2017-08-04 15:00:00   NaN   NaN  19.074074      15  \n",
       "2017-08-04 16:00:00   NaN   NaN  18.703704      16  \n",
       "2017-08-04 17:00:00   NaN   NaN  17.592593      17  \n",
       "2017-08-04 18:00:00  69.0  58.0  16.851852      18  \n",
       "2017-08-04 19:00:00   NaN   NaN  16.111111      19  \n",
       "2017-08-04 20:00:00   NaN   NaN  15.925926      20  \n",
       "2017-08-04 21:00:00   NaN   NaN  15.925926      21  \n",
       "2017-08-04 22:00:00   NaN   NaN  15.555556      22  \n",
       "2017-08-04 23:00:00   NaN   NaN  15.185185      23  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"DATE\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be the same result we achieved earlier based on string slicing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding outliers from the data\n",
    "\n",
    "Finally, we are ready to do some real data analytics and check whether we are able to find out if there are any outliers in our data suggesting to have a storm (meaning strong winds in this case).\n",
    "\n",
    "Here, we define an outlier if the **wind speed is 2 times the standard deviation higher than the average wind speed** (column `SPEED`).\n",
    "\n",
    "- Let's first find out what is the standard deviation and the mean of the Wind speed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Std: 1.6405694308360985\n",
      "Mean: 5.153377777777777\n"
     ]
    }
   ],
   "source": [
    "# Calculate standard deviation and average wind speed\n",
    "std_wind = hourly_data['SPEED'].std()\n",
    "avg_wind = hourly_data['SPEED'].mean()\n",
    "print('Std:', std_wind)\n",
    "print('Mean:', avg_wind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okey, so the variance in the windspeed tend to be approximately 1.6 meters per second, and the wind speed is approximately 5.2 m/s. \n",
    "\n",
    "- Hence, the threshold for a wind speed to be an outlier with our criteria is:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper threshold for outlier: 8.434516639449974\n"
     ]
    }
   ],
   "source": [
    "# Calculate the upper threshold for an outlier\n",
    "upper_threshold = avg_wind + (std_wind*2)\n",
    "print('Upper threshold for outlier:', upper_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's finally create a column called `OUTLIER` which we update with `True` value, if the windspeed is an outlier, and `False`, if it is not. We do this again by iterating over the rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           DIR      GUST     SPEED       TEMP     TEMP_C     TIME_DH  OUTLIER\n",
      "0   104.666667       NaN  2.533227  58.666667  14.814815  2017080400    False\n",
      "1   111.000000       NaN  3.129280  59.666667  15.370370  2017080401    False\n",
      "2   119.333333   5.81152  4.321387  59.000000  15.000000  2017080402    False\n",
      "3    92.666667   5.36448  3.874347  59.000000  15.000000  2017080403    False\n",
      "4    87.333333   6.70560  4.619413  58.666667  14.814815  2017080404    False\n",
      "5   403.000000   7.59968  5.364480  58.666667  14.814815  2017080405    False\n",
      "6   110.333333  10.28192  6.854613  58.666667  14.814815  2017080406    False\n",
      "7   403.000000   9.83488  6.109547  58.666667  14.814815  2017080407    False\n",
      "8   405.000000   6.70560  3.874347  58.666667  14.814815  2017080408    False\n",
      "9   695.666667       NaN  3.129280  59.666667  15.370370  2017080409    False\n",
      "10  225.000000   5.81152  4.768427  61.666667  16.481481  2017080410    False\n",
      "11  241.666667   8.49376  5.513493  64.000000  17.777778  2017080411    False\n",
      "12  228.333333   6.70560  5.960533  66.000000  18.888889  2017080412    False\n",
      "13  229.666667   8.94080  7.152640  67.333333  19.629630  2017080413    False\n",
      "14  228.666667  12.96416  8.940800  68.333333  20.185185  2017080414     True\n",
      "15  218.333333  10.72896  7.450667  66.333333  19.074074  2017080415    False\n",
      "16  214.666667  10.28192  7.152640  65.666667  18.703704  2017080416    False\n",
      "17  209.666667   8.94080  7.003627  63.666667  17.592593  2017080417    False\n",
      "18  211.333333  10.28192  5.662507  62.333333  16.851852  2017080418    False\n",
      "19  203.000000   5.81152  4.023360  61.000000  16.111111  2017080419    False\n",
      "20  198.000000   5.36448  4.023360  60.666667  15.925926  2017080420    False\n",
      "21  186.666667       NaN  3.874347  60.666667  15.925926  2017080421    False\n",
      "22  189.000000   6.70560  4.619413  60.000000  15.555556  2017080422    False\n",
      "23  193.333333   4.91744  3.725333  59.333333  15.185185  2017080423    False\n"
     ]
    }
   ],
   "source": [
    "# Create an empty column for outlier info\n",
    "hourly_data['OUTLIER'] = None\n",
    "\n",
    "# Iterate over rows\n",
    "for idx, row in hourly_data.iterrows():\n",
    "    # Update the 'Outlier' column with True if the wind speed is higher than our threshold value\n",
    "    if row['SPEED'] > upper_threshold :\n",
    "        hourly_data.loc[idx, 'OUTLIER'] = True\n",
    "    else:\n",
    "        hourly_data.loc[idx, 'OUTLIER'] = False\n",
    "\n",
    "# Let's see what we have\n",
    "print(hourly_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okey now we have at least many False values in our `OUTLIER` -column but there seems to be also one True!\n",
    "\n",
    "- Let's select the rows with potential storm:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           DIR      GUST   SPEED       TEMP     TEMP_C     TIME_DH  OUTLIER\n",
      "14  228.666667  12.96416  8.9408  68.333333  20.185185  2017080414     True\n"
     ]
    }
   ],
   "source": [
    "# Select rows that were determined as outliers\n",
    "storm = hourly_data.loc[hourly_data['OUTLIER'] == True]\n",
    "print(storm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okey, so indeed, there was one outlier in our data but the wind during that time wasn't that strong as the average speed was only approximately 9 m/s. This is not too strange as we were only looking at data from a single day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeating the data analysis with larger dataset\n",
    "\n",
    "Let's continue by executing the steps that we have written this far and use it to explore outlier winds based on whole month of August 2017. So far, we have only processed data for one single day (4th of August).\n",
    "\n",
    "For this purpose, we change the input file to be **`6591337447542dat_August.txt`** (full record for August 2017). You can find the file in here: [data/6591337447542dat_August.txt](data/6591337447542dat_August.txt).\n",
    "\n",
    "- Here we will repeat all the steps that we did earlier in one code block so that you can see the full picture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Filepath\n",
    "fp = \"data/6591337447542dat_August.txt\"\n",
    "\n",
    "# Read data using varying amount of spaces as separator and specifying * characters as NoData values\n",
    "data = pd.read_csv(fp, sep='\\s+', na_values=['*', '**', '***', '****', '*****', '******'])\n",
    "\n",
    "# Select only specific columns\n",
    "select_cols = ['YR--MODAHRMN', 'DIR', 'SPD', 'GUS','TEMP', 'MAX', 'MIN']\n",
    "data = data[select_cols]\n",
    "\n",
    "# Rename the columns\n",
    "name_conversion_dict = {'YR--MODAHRMN': 'TIME', 'SPD': 'SPEED', 'GUS': 'GUST'}\n",
    "data = data.rename(columns=name_conversion_dict)\n",
    "\n",
    "# Create column\n",
    "col_name = 'TEMP_C'\n",
    "data[col_name] = None\n",
    "\n",
    "# Iterete over rows and convert tempetarues from Fahrenheits to Celsius\n",
    "for idx, row in data.iterrows():\n",
    "    celsius = fahr_to_celsius(row['TEMP'])\n",
    "    data.loc[idx, col_name] = celsius\n",
    "\n",
    "# Convert wind speeds from miles to meters per second\n",
    "data['SPEED'] = data['SPEED']*0.44704\n",
    "data['GUST'] = data['GUST']*0.44704\n",
    "\n",
    "# Convert TIME to string and parse date and hour info from the time\n",
    "data['TIME_STR'] = data['TIME'].astype(str)\n",
    "data['TIME_DH'] = data['TIME_STR'].str.slice(start=0, stop=10)\n",
    "\n",
    "# Create empty column for aggregated data\n",
    "hourly_data = pd.DataFrame()\n",
    "\n",
    "# Specify the columns which will be used in calculation\n",
    "mean_cols = ['DIR', 'SPEED', 'GUST', 'TEMP', 'TEMP_C']\n",
    "\n",
    "# Group the values by hour\n",
    "grouped = data.groupby('TIME_DH')\n",
    "\n",
    "# Iterate over groups and update the aggregated DataFrame\n",
    "for key, group in grouped:\n",
    "    # Calculate the mean values\n",
    "    mean_values = group[mean_cols].mean()\n",
    "    \n",
    "    # Add the time to the Series\n",
    "    mean_values['TIME_DH'] = key\n",
    "    \n",
    "    # Add the aggregated values into the DataFrame\n",
    "    hourly_data  = hourly_data .append(mean_values, ignore_index=True)\n",
    "\n",
    "# Calculate the outlier threshold for the new dataset\n",
    "std_wind = hourly_data['SPEED'].std()\n",
    "avg_wind = hourly_data['SPEED'].mean()\n",
    "upper_threshold = avg_wind + (std_wind*2)\n",
    "\n",
    "# Detect the outliers\n",
    "hourly_data['OUTLIER'] = None\n",
    "\n",
    "for idx, row in hourly_data.iterrows():\n",
    "    if row['SPEED'] > upper_threshold:\n",
    "        hourly_data.loc[idx, 'OUTLIER'] = True\n",
    "    else:\n",
    "        hourly_data.loc[idx, 'OUTLIER'] = False\n",
    "        \n",
    "# Select days with strong winds\n",
    "storm = hourly_data.loc[hourly_data['OUTLIER'] == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the analysis with our new dataset, let's explore and see we have.\n",
    "\n",
    "- Let's start by checking if the average and standard deviation of the windspeed differ from the previous ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Std: 2.1405899770297245\n",
      "Mean: 4.1990832704402505\n"
     ]
    }
   ],
   "source": [
    "# Windspeed statistics\n",
    "print('Std:', std_wind)\n",
    "print('Mean:', avg_wind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okey so they are indeed different now! With larger dataset the average wind speed is 4.2 m/s (compared to 5.2 m/s previously). \n",
    "\n",
    "- Let's see what we have now in our **`storm`** -variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            DIR      GUST      SPEED       TEMP     TEMP_C     TIME_DH  \\\n",
      "10   210.666667  12.51712   9.089813  73.000000  22.777778  2017080110   \n",
      "11   212.000000  11.62304   8.940800  73.000000  22.777778  2017080111   \n",
      "12   205.666667  12.51712   9.089813  72.333333  22.407407  2017080112   \n",
      "86   228.666667  12.96416   8.940800  68.333333  20.185185  2017080414   \n",
      "104  204.333333  11.17600   8.791787  67.666667  19.814815  2017080508   \n",
      "132  237.666667  13.85824   9.387840  61.333333  16.296296  2017080612   \n",
      "230  217.000000  12.51712   8.642773  71.000000  21.666667  2017081014   \n",
      "280  700.666667  26.82240   8.791787  66.333333  19.074074  2017081216   \n",
      "301  210.000000       NaN   9.611360  69.000000  20.555556  2017081313   \n",
      "302  200.000000       NaN   8.493760  67.000000  19.444444  2017081314   \n",
      "444  195.666667  10.72896   8.493760  71.666667  22.037037  2017081914   \n",
      "445  204.666667  12.51712   8.940800  69.666667  20.925926  2017081915   \n",
      "559  328.666667  13.41120   8.493760  58.666667  14.814815  2017082409   \n",
      "560  329.333333  13.85824   8.493760  60.666667  15.925926  2017082410   \n",
      "563  329.666667  13.41120   9.238827  61.333333  16.296296  2017082413   \n",
      "564  550.000000       NaN   8.493760  59.333333  15.185185  2017082414   \n",
      "686  214.000000  13.41120   9.089813  63.000000  17.222222  2017082916   \n",
      "687  210.666667  11.62304   8.791787  62.666667  17.037037  2017082917   \n",
      "704  203.666667   8.04672   8.493760  65.333333  18.518519  2017083010   \n",
      "705  218.333333  13.41120   8.940800  66.000000  18.888889  2017083011   \n",
      "706  215.666667  14.52880  10.579947  64.333333  17.962963  2017083012   \n",
      "707  217.666667  12.07008   9.089813  64.333333  17.962963  2017083013   \n",
      "\n",
      "     OUTLIER  \n",
      "10      True  \n",
      "11      True  \n",
      "12      True  \n",
      "86      True  \n",
      "104     True  \n",
      "132     True  \n",
      "230     True  \n",
      "280     True  \n",
      "301     True  \n",
      "302     True  \n",
      "444     True  \n",
      "445     True  \n",
      "559     True  \n",
      "560     True  \n",
      "563     True  \n",
      "564     True  \n",
      "686     True  \n",
      "687     True  \n",
      "704     True  \n",
      "705     True  \n",
      "706     True  \n",
      "707     True  \n"
     ]
    }
   ],
   "source": [
    "print(storm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okey, interesting! Now we can see the the days and hours when it has been stormy in August 2017.\n",
    "It seems that the storms have usually been during the day time. Let's check if this is the case.\n",
    "\n",
    "We can easily count how many stormy observations for different hour of the day there has been by\n",
    "using a [**`value_counts()`**](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.value_counts.html) -function that calculates how many observations per certain value there are in a certain column (works best for categorigal data).\n",
    "\n",
    "- Let's see the counts for different hours of the day\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average wind speed may not be the perfect measure to find extreme weather conditions. Gust might usually be a better measure for that purpose.\n",
    "\n",
    "- Let's see what were the strongest gust winds in our dataset by sorting the values using **`sort_values()`** -function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            DIR      GUST      SPEED       TEMP     TEMP_C     TIME_DH  \\\n",
      "280  700.666667  26.82240   8.791787  66.333333  19.074074  2017081216   \n",
      "706  215.666667  14.52880  10.579947  64.333333  17.962963  2017083012   \n",
      "132  237.666667  13.85824   9.387840  61.333333  16.296296  2017080612   \n",
      "560  329.333333  13.85824   8.493760  60.666667  15.925926  2017082410   \n",
      "559  328.666667  13.41120   8.493760  58.666667  14.814815  2017082409   \n",
      "705  218.333333  13.41120   8.940800  66.000000  18.888889  2017083011   \n",
      "686  214.000000  13.41120   9.089813  63.000000  17.222222  2017082916   \n",
      "563  329.666667  13.41120   9.238827  61.333333  16.296296  2017082413   \n",
      "86   228.666667  12.96416   8.940800  68.333333  20.185185  2017080414   \n",
      "10   210.666667  12.51712   9.089813  73.000000  22.777778  2017080110   \n",
      "445  204.666667  12.51712   8.940800  69.666667  20.925926  2017081915   \n",
      "230  217.000000  12.51712   8.642773  71.000000  21.666667  2017081014   \n",
      "12   205.666667  12.51712   9.089813  72.333333  22.407407  2017080112   \n",
      "707  217.666667  12.07008   9.089813  64.333333  17.962963  2017083013   \n",
      "11   212.000000  11.62304   8.940800  73.000000  22.777778  2017080111   \n",
      "687  210.666667  11.62304   8.791787  62.666667  17.037037  2017082917   \n",
      "104  204.333333  11.17600   8.791787  67.666667  19.814815  2017080508   \n",
      "444  195.666667  10.72896   8.493760  71.666667  22.037037  2017081914   \n",
      "704  203.666667   8.04672   8.493760  65.333333  18.518519  2017083010   \n",
      "301  210.000000       NaN   9.611360  69.000000  20.555556  2017081313   \n",
      "302  200.000000       NaN   8.493760  67.000000  19.444444  2017081314   \n",
      "564  550.000000       NaN   8.493760  59.333333  15.185185  2017082414   \n",
      "\n",
      "     OUTLIER  \n",
      "280     True  \n",
      "706     True  \n",
      "132     True  \n",
      "560     True  \n",
      "559     True  \n",
      "705     True  \n",
      "686     True  \n",
      "563     True  \n",
      "86      True  \n",
      "10      True  \n",
      "445     True  \n",
      "230     True  \n",
      "12      True  \n",
      "707     True  \n",
      "11      True  \n",
      "687     True  \n",
      "104     True  \n",
      "444     True  \n",
      "704     True  \n",
      "301     True  \n",
      "302     True  \n",
      "564     True  \n"
     ]
    }
   ],
   "source": [
    "# Sort values in descending order\n",
    "gust_sort = storm.sort_values(by='GUST', ascending=False)\n",
    "\n",
    "# Let's see what we have\n",
    "print(gust_sort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There! There was one hour with quite extraordinary gust wind in our data happening at 12th of August in 2017 - the day when [Kiira hit Helsinki](https://yle.fi/uutiset/osasto/news/saturday_night_storm_downs_trees_cuts_electricity_in_the_south/9773250).\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
